=== Próba 1/20 ===
Parametry: {'batch_size': 512, 'batchnorm': True, 'dropout': 0.0, 'lr': 0.001}
[1/10] Train Loss: 0.189505
[2/10] Train Loss: 0.103461
[3/10] Train Loss: 0.055021
[4/10] Train Loss: 0.034172
[5/10] Train Loss: 0.030530
[6/10] Train Loss: 0.027020
[7/10] Train Loss: 0.023585
[8/10] Train Loss: 0.023948
[9/10] Train Loss: 0.021486
[10/10] Train Loss: 0.020909
Nowy najlepszy model zapisany jako: best_model_trial_01_drop0.0_bs512_lr0.001_bnTrue.pt

=== Próba 2/20 ===
Parametry: {'batch_size': 512, 'batchnorm': True, 'dropout': 0.0, 'lr': 0.0005}
[1/10] Train Loss: 0.226658
[2/10] Train Loss: 0.131814
[3/10] Train Loss: 0.115477
[4/10] Train Loss: 0.104309
[5/10] Train Loss: 0.088294
[6/10] Train Loss: 0.062366
[7/10] Train Loss: 0.029416
[8/10] Train Loss: 0.021060
[9/10] Train Loss: 0.018551
[10/10] Train Loss: 0.020911

=== Próba 3/20 ===
Parametry: {'batch_size': 512, 'batchnorm': True, 'dropout': 0.1, 'lr': 0.001}
[1/10] Train Loss: 0.296022
[2/10] Train Loss: 0.223904
[3/10] Train Loss: 0.202294
[4/10] Train Loss: 0.177325
[5/10] Train Loss: 0.158135
[6/10] Train Loss: 0.124920
[7/10] Train Loss: 0.105303
[8/10] Train Loss: 0.125957
[9/10] Train Loss: 0.102708
[10/10] Train Loss: 0.100800

=== Próba 4/20 ===
Parametry: {'batch_size': 512, 'batchnorm': True, 'dropout': 0.1, 'lr': 0.0005}
[1/10] Train Loss: 0.332691
[2/10] Train Loss: 0.234065
[3/10] Train Loss: 0.216945
[4/10] Train Loss: 0.203479
[5/10] Train Loss: 0.190104
[6/10] Train Loss: 0.176956
[7/10] Train Loss: 0.173144
[8/10] Train Loss: 0.170471
[9/10] Train Loss: 0.166498
[10/10] Train Loss: 0.163391

=== Próba 5/20 ===
Parametry: {'batch_size': 512, 'batchnorm': True, 'dropout': 0.2, 'lr': 0.001}
[1/10] Train Loss: 0.348521
[2/10] Train Loss: 0.279740
[3/10] Train Loss: 0.261901
[4/10] Train Loss: 0.253883
[5/10] Train Loss: 0.250625
[6/10] Train Loss: 0.244009
[7/10] Train Loss: 0.237898
[8/10] Train Loss: 0.235707
[9/10] Train Loss: 0.232495
[10/10] Train Loss: 0.233272

=== Próba 6/20 ===
Parametry: {'batch_size': 512, 'batchnorm': True, 'dropout': 0.2, 'lr': 0.0005}
[1/10] Train Loss: 0.385307
[2/10] Train Loss: 0.303643
[3/10] Train Loss: 0.276953
[4/10] Train Loss: 0.264576
[5/10] Train Loss: 0.257062
[6/10] Train Loss: 0.252345
[7/10] Train Loss: 0.246776
[8/10] Train Loss: 0.241197
[9/10] Train Loss: 0.236922
[10/10] Train Loss: 0.234177

=== Próba 7/20 ===
Parametry: {'batch_size': 512, 'batchnorm': False, 'dropout': 0.0, 'lr': 0.001}
[1/10] Train Loss: 0.183748
[2/10] Train Loss: 0.093950
[3/10] Train Loss: 0.082934
[4/10] Train Loss: 0.028729
[5/10] Train Loss: 0.026228
[6/10] Train Loss: 0.031280
[7/10] Train Loss: 0.040765
[8/10] Train Loss: 0.026348
[9/10] Train Loss: 0.024460
[10/10] Train Loss: 0.036733
Nowy najlepszy model zapisany jako: best_model_trial_07_drop0.0_bs512_lr0.001_bnFalse.pt

=== Próba 8/20 ===
Parametry: {'batch_size': 512, 'batchnorm': False, 'dropout': 0.0, 'lr': 0.0005}
[1/10] Train Loss: 0.213818
[2/10] Train Loss: 0.087849
[3/10] Train Loss: 0.041547
[4/10] Train Loss: 0.029550
[5/10] Train Loss: 0.027344
[6/10] Train Loss: 0.023138
[7/10] Train Loss: 0.034146
[8/10] Train Loss: 0.014244
[9/10] Train Loss: 0.019549
[10/10] Train Loss: 0.023086
Nowy najlepszy model zapisany jako: best_model_trial_08_drop0.0_bs512_lr0.0005_bnFalse.pt

=== Próba 9/20 ===
Parametry: {'batch_size': 512, 'batchnorm': False, 'dropout': 0.1, 'lr': 0.001}
[1/10] Train Loss: 0.294824
[2/10] Train Loss: 0.200482
[3/10] Train Loss: 0.193646
[4/10] Train Loss: 0.153021
[5/10] Train Loss: 0.147277
[6/10] Train Loss: 0.136397
[7/10] Train Loss: 0.130939
[8/10] Train Loss: 0.113761
[9/10] Train Loss: 0.101020
[10/10] Train Loss: 0.116229

=== Próba 10/20 ===
Parametry: {'batch_size': 512, 'batchnorm': False, 'dropout': 0.1, 'lr': 0.0005}
[1/10] Train Loss: 0.338627
[2/10] Train Loss: 0.231215
[3/10] Train Loss: 0.210901
[4/10] Train Loss: 0.191378
[5/10] Train Loss: 0.144780
[6/10] Train Loss: 0.126510
[7/10] Train Loss: 0.127964
[8/10] Train Loss: 0.112069
[9/10] Train Loss: 0.104512
[10/10] Train Loss: 0.122552


=== Próba 11/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': True, 'dropout': 0.0, 'lr': 0.001}
[1/10] Train Loss: 0.226967
[2/10] Train Loss: 0.122447
[3/10] Train Loss: 0.096627
[4/10] Train Loss: 0.048356
[5/10] Train Loss: 0.035515
[6/10] Train Loss: 0.025882
[7/10] Train Loss: 0.027398
[8/10] Train Loss: 0.032520
[9/10] Train Loss: 0.029848
[10/10] Train Loss: 0.032545
Nowy najlepszy model zapisany jako: best_model_trial_01_drop0.0_bs1024_lr0.001_bnTrue.pt

=== Próba 12/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': True, 'dropout': 0.0, 'lr': 0.0005}
[1/10] Train Loss: 0.276599
[2/10] Train Loss: 0.149550
[3/10] Train Loss: 0.121775
[4/10] Train Loss: 0.096619
[5/10] Train Loss: 0.063233
[6/10] Train Loss: 0.031069
[7/10] Train Loss: 0.020915
[8/10] Train Loss: 0.019929
[9/10] Train Loss: 0.019871
[10/10] Train Loss: 0.018525
Nowy najlepszy model zapisany jako: best_model_trial_02_drop0.0_bs1024_lr0.0005_bnTrue.pt

=== Próba 13/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': True, 'dropout': 0.1, 'lr': 0.001}
[1/10] Train Loss: 0.325531
[2/10] Train Loss: 0.232213
[3/10] Train Loss: 0.207738
[4/10] Train Loss: 0.190726
[5/10] Train Loss: 0.175858
[6/10] Train Loss: 0.156554
[7/10] Train Loss: 0.118630
[8/10] Train Loss: 0.103862
[9/10] Train Loss: 0.116961
[10/10] Train Loss: 0.106028

=== Próba 14/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': True, 'dropout': 0.1, 'lr': 0.0005}
[1/10] Train Loss: 0.374506
[2/10] Train Loss: 0.259352
[3/10] Train Loss: 0.233261
[4/10] Train Loss: 0.220345
[5/10] Train Loss: 0.211721
[6/10] Train Loss: 0.195984
[7/10] Train Loss: 0.181495
[8/10] Train Loss: 0.169484
[9/10] Train Loss: 0.153025
[10/10] Train Loss: 0.134753

=== Próba 15/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': True, 'dropout': 0.2, 'lr': 0.001}
[1/10] Train Loss: 0.377604
[2/10] Train Loss: 0.290942
[3/10] Train Loss: 0.266327
[4/10] Train Loss: 0.254628
[5/10] Train Loss: 0.243578
[6/10] Train Loss: 0.238320
[7/10] Train Loss: 0.230253
[8/10] Train Loss: 0.227860
[9/10] Train Loss: 0.223471
[10/10] Train Loss: 0.215149

=== Próba 16/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': True, 'dropout': 0.2, 'lr': 0.0005}
[1/10] Train Loss: 0.437169
[2/10] Train Loss: 0.332565
[3/10] Train Loss: 0.308111
[4/10] Train Loss: 0.292834
[5/10] Train Loss: 0.281573
[6/10] Train Loss: 0.271423
[7/10] Train Loss: 0.265550
[8/10] Train Loss: 0.258086
[9/10] Train Loss: 0.250784
[10/10] Train Loss: 0.244429

=== Próba 17/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': False, 'dropout': 0.0, 'lr': 0.001}
[1/10] Train Loss: 0.211159
[2/10] Train Loss: 0.087906
[3/10] Train Loss: 0.068635
[4/10] Train Loss: 0.026218
[5/10] Train Loss: 0.031740
[6/10] Train Loss: 0.035423
[7/10] Train Loss: 0.031311
[8/10] Train Loss: 0.017086
[9/10] Train Loss: 0.016064
[10/10] Train Loss: 0.023388
Nowy najlepszy model zapisany jako: best_model_trial_07_drop0.0_bs1024_lr0.001_bnFalse.pt

=== Próba 18/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': False, 'dropout': 0.0, 'lr': 0.0005}
[1/10] Train Loss: 0.278862
[2/10] Train Loss: 0.121747
[3/10] Train Loss: 0.076282
[4/10] Train Loss: 0.042745
[5/10] Train Loss: 0.022662
[6/10] Train Loss: 0.024621
[7/10] Train Loss: 0.030887
[8/10] Train Loss: 0.017458
[9/10] Train Loss: 0.021240
[10/10] Train Loss: 0.021734

=== Próba 19/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': False, 'dropout': 0.1, 'lr': 0.001}
[1/10] Train Loss: 0.328209
[2/10] Train Loss: 0.216628
[3/10] Train Loss: 0.187781
[4/10] Train Loss: 0.163938
[5/10] Train Loss: 0.138793
[6/10] Train Loss: 0.113754
[7/10] Train Loss: 0.098075
[8/10] Train Loss: 0.122053
[9/10] Train Loss: 0.124103
[10/10] Train Loss: 0.115125

=== Próba 20/20 ===
Parametry: {'batch_size': 1024, 'batchnorm': False, 'dropout': 0.1, 'lr': 0.0005}
[1/10] Train Loss: 0.383846
[2/10] Train Loss: 0.255146
[3/10] Train Loss: 0.227278
[4/10] Train Loss: 0.196662
[5/10] Train Loss: 0.173090
[6/10] Train Loss: 0.156474
[7/10] Train Loss: 0.130130
[8/10] Train Loss: 0.119554
[9/10] Train Loss: 0.115244
[10/10] Train Loss: 0.124809